{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/robert/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/robert/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# down load nltk data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# setting stopword\n",
    "stop = stopwords.words('english')\n",
    "stop.remove('no')\n",
    "stop.remove('not')\n",
    "\n",
    "# setting lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "justice_path = './dataset/'\n",
    "justice_data = pd.read_csv(os.path.join(justice_path,'justice.csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Preprocessing for Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 subset of interested columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_intersted = ['ID', \n",
    "                     'first_party',\n",
    "                     'second_party',\n",
    "                     'facts',\n",
    "                     'first_party_winner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "justice_data_new = justice_data[columns_intersted].copy(deep=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2A quick investigation of the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2762</th>\n",
       "      <td>61978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In Re Winship</td>\n",
       "      <td>&lt;p&gt;At age twelve, Samuel Winship was arrested ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID first_party   second_party  \\\n",
       "2762  61978         NaN  In Re Winship   \n",
       "\n",
       "                                                  facts first_party_winner  \n",
       "2762  <p>At age twelve, Samuel Winship was arrested ...               True  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "justice_data_new[justice_data_new['first_party'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>54848</td>\n",
       "      <td>In re Bauer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;Pro se petitioner Frederick W. Bauer sought...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  first_party second_party  \\\n",
       "1257  54848  In re Bauer          NaN   \n",
       "\n",
       "                                                  facts first_party_winner  \n",
       "1257  <p>Pro se petitioner Frederick W. Bauer sought...              False  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "justice_data_new[justice_data_new['second_party'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>51803</td>\n",
       "      <td>United States</td>\n",
       "      <td>California</td>\n",
       "      <td>&lt;p&gt;Channel Islands National Monument is a nati...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>54908</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>Maine</td>\n",
       "      <td>&lt;p&gt;In 1977, a dispute between New Hampshire an...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>55282</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>United States</td>\n",
       "      <td>&lt;p&gt;Alaska and the United States disputed owner...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>55334</td>\n",
       "      <td>Bank of China, New York Branch</td>\n",
       "      <td>NBM L.L.C., et al.</td>\n",
       "      <td>&lt;p&gt;Bank of China alleged that John Chou and Sh...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>55514</td>\n",
       "      <td>State of New Jersey</td>\n",
       "      <td>State of Delaware</td>\n",
       "      <td>&lt;p&gt;When British Petroleum (BP) wanted to build...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>55652</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>&lt;p&gt;Several states belonging to the Southeast I...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>55781</td>\n",
       "      <td>Montana</td>\n",
       "      <td>Wyoming and North Dakota</td>\n",
       "      <td>&lt;p&gt;1950, Montana, Wyoming and North Dakota sig...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2528</th>\n",
       "      <td>60033</td>\n",
       "      <td>Dusky</td>\n",
       "      <td>United States</td>\n",
       "      <td>&lt;p&gt;Dusky was charged with kidnapping and rape....</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2631</th>\n",
       "      <td>61030</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>Katzenbach</td>\n",
       "      <td>&lt;p&gt;The Voting Rights Act of 1965 prevented sta...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2787</th>\n",
       "      <td>62121</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>&lt;p&gt;The Louisiana State Constitution and Code o...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>62377</td>\n",
       "      <td>The Civil Rights Cases</td>\n",
       "      <td>Various appellants</td>\n",
       "      <td>&lt;p&gt;The Civil Rights Act of 1875 affirmed the e...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903</th>\n",
       "      <td>62500</td>\n",
       "      <td>Albert Yakus</td>\n",
       "      <td>United States</td>\n",
       "      <td>&lt;p&gt;In 1942, Congress enacted the Emergency Pri...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3080</th>\n",
       "      <td>62911</td>\n",
       "      <td>State of Texas</td>\n",
       "      <td>State of New Mexico and State of Colorado</td>\n",
       "      <td>&lt;p&gt;The Rio Grande originates in Colorado, flow...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3183</th>\n",
       "      <td>63090</td>\n",
       "      <td>New York State Rifle and Pistol Association, I...</td>\n",
       "      <td>City of New York, New York, et al.</td>\n",
       "      <td>&lt;p&gt;The State of New York law prohibits the pos...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3203</th>\n",
       "      <td>63137</td>\n",
       "      <td>Retirement Plans Committee of IBM, et al.</td>\n",
       "      <td>Larry W. Jander, et al.</td>\n",
       "      <td>&lt;p&gt;In &lt;a href=\"https://www.oyez.org/cases/2013...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                        first_party  \\\n",
       "223   51803                                      United States   \n",
       "1322  54908                                      New Hampshire   \n",
       "1674  55282                                             Alaska   \n",
       "1721  55334                     Bank of China, New York Branch   \n",
       "1890  55514                                State of New Jersey   \n",
       "2023  55652                                            Alabama   \n",
       "2137  55781                                            Montana   \n",
       "2528  60033                                              Dusky   \n",
       "2631  61030                                     South Carolina   \n",
       "2787  62121                                            Johnson   \n",
       "2875  62377                             The Civil Rights Cases   \n",
       "2903  62500                                       Albert Yakus   \n",
       "3080  62911                                     State of Texas   \n",
       "3183  63090  New York State Rifle and Pistol Association, I...   \n",
       "3203  63137          Retirement Plans Committee of IBM, et al.   \n",
       "\n",
       "                                   second_party  \\\n",
       "223                                  California   \n",
       "1322                                      Maine   \n",
       "1674                              United States   \n",
       "1721                         NBM L.L.C., et al.   \n",
       "1890                          State of Delaware   \n",
       "2023                             North Carolina   \n",
       "2137                   Wyoming and North Dakota   \n",
       "2528                              United States   \n",
       "2631                                 Katzenbach   \n",
       "2787                                  Louisiana   \n",
       "2875                         Various appellants   \n",
       "2903                              United States   \n",
       "3080  State of New Mexico and State of Colorado   \n",
       "3183         City of New York, New York, et al.   \n",
       "3203                    Larry W. Jander, et al.   \n",
       "\n",
       "                                                  facts first_party_winner  \n",
       "223   <p>Channel Islands National Monument is a nati...                NaN  \n",
       "1322  <p>In 1977, a dispute between New Hampshire an...                NaN  \n",
       "1674  <p>Alaska and the United States disputed owner...                NaN  \n",
       "1721  <p>Bank of China alleged that John Chou and Sh...                NaN  \n",
       "1890  <p>When British Petroleum (BP) wanted to build...                NaN  \n",
       "2023  <p>Several states belonging to the Southeast I...                NaN  \n",
       "2137  <p>1950, Montana, Wyoming and North Dakota sig...                NaN  \n",
       "2528  <p>Dusky was charged with kidnapping and rape....                NaN  \n",
       "2631  <p>The Voting Rights Act of 1965 prevented sta...                NaN  \n",
       "2787  <p>The Louisiana State Constitution and Code o...                NaN  \n",
       "2875  <p>The Civil Rights Act of 1875 affirmed the e...                NaN  \n",
       "2903  <p>In 1942, Congress enacted the Emergency Pri...                NaN  \n",
       "3080  <p>The Rio Grande originates in Colorado, flow...                NaN  \n",
       "3183  <p>The State of New York law prohibits the pos...                NaN  \n",
       "3203  <p>In <a href=\"https://www.oyez.org/cases/2013...                NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "justice_data_new[justice_data_new['first_party_winner'].isna()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a results, there are NaN values in our data. We should remove/drop these noise rows."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 drop the rows with NaN or missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "justice_data_new.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50606</td>\n",
       "      <td>Jane Roe</td>\n",
       "      <td>Henry Wade</td>\n",
       "      <td>&lt;p&gt;In 1970, Jane Roe (a fictional name used in...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50613</td>\n",
       "      <td>Peter Stanley, Sr.</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>&lt;p&gt;Joan Stanley had three children with Peter ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50623</td>\n",
       "      <td>John Giglio</td>\n",
       "      <td>United States</td>\n",
       "      <td>&lt;p&gt;John Giglio was convicted of passing forged...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50632</td>\n",
       "      <td>Sally Reed</td>\n",
       "      <td>Cecil Reed</td>\n",
       "      <td>&lt;p&gt;The Idaho Probate Code specified that \"male...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50643</td>\n",
       "      <td>Marvin Miller</td>\n",
       "      <td>California</td>\n",
       "      <td>&lt;p&gt;Miller, after conducting a mass mailing cam...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3298</th>\n",
       "      <td>63324</td>\n",
       "      <td>United States</td>\n",
       "      <td>Refugio Palomar-Santiago</td>\n",
       "      <td>&lt;p&gt;Refugio Palomar-Santiago, a Mexican nationa...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3299</th>\n",
       "      <td>63323</td>\n",
       "      <td>Tarahrick Terry</td>\n",
       "      <td>United States</td>\n",
       "      <td>&lt;p&gt;Tarahrick Terry pleaded guilty to one count...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3300</th>\n",
       "      <td>63331</td>\n",
       "      <td>United States</td>\n",
       "      <td>Joshua James Cooley</td>\n",
       "      <td>&lt;p&gt;Joshua James Cooley was parked in his picku...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3301</th>\n",
       "      <td>63332</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>&lt;p&gt;This is an ongoing case of original jurisdi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3302</th>\n",
       "      <td>63335</td>\n",
       "      <td>PennEast Pipeline Co. LLC</td>\n",
       "      <td>New Jersey, et al.</td>\n",
       "      <td>&lt;p&gt;The Natural Gas Act (NGA), 15 U.S.C. §§ 717...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3286 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                first_party              second_party  \\\n",
       "0     50606                   Jane Roe                Henry Wade   \n",
       "1     50613        Peter Stanley, Sr.                   Illinois   \n",
       "2     50623               John Giglio              United States   \n",
       "3     50632                 Sally Reed                Cecil Reed   \n",
       "4     50643              Marvin Miller                California   \n",
       "...     ...                        ...                       ...   \n",
       "3298  63324              United States  Refugio Palomar-Santiago   \n",
       "3299  63323            Tarahrick Terry             United States   \n",
       "3300  63331              United States       Joshua James Cooley   \n",
       "3301  63332                    Florida                   Georgia   \n",
       "3302  63335  PennEast Pipeline Co. LLC        New Jersey, et al.   \n",
       "\n",
       "                                                  facts first_party_winner  \n",
       "0     <p>In 1970, Jane Roe (a fictional name used in...               True  \n",
       "1     <p>Joan Stanley had three children with Peter ...               True  \n",
       "2     <p>John Giglio was convicted of passing forged...               True  \n",
       "3     <p>The Idaho Probate Code specified that \"male...               True  \n",
       "4     <p>Miller, after conducting a mass mailing cam...               True  \n",
       "...                                                 ...                ...  \n",
       "3298  <p>Refugio Palomar-Santiago, a Mexican nationa...               True  \n",
       "3299  <p>Tarahrick Terry pleaded guilty to one count...              False  \n",
       "3300  <p>Joshua James Cooley was parked in his picku...               True  \n",
       "3301  <p>This is an ongoing case of original jurisdi...              False  \n",
       "3302  <p>The Natural Gas Act (NGA), 15 U.S.C. §§ 717...               True  \n",
       "\n",
       "[3286 rows x 5 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "justice_data_new#['facts'][1]#[justice_data_new['second_party'].isna()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clean(text):\n",
    "  text = text.lower()\n",
    "  text = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?|p\", \"\", text)\n",
    "  text_tokens = word_tokenize(text)\n",
    "  text_stop = [word for word in text_tokens if word not in (stop)]\n",
    "  text_new = ' '.join(text_stop)\n",
    "  return text_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clean_1(first_party, second_party, fact):\n",
    "    \"\"\"This is to clean the facts. Will remove the first party and second party name\n",
    "    \n",
    "    Args:\n",
    "        first_party:    first party name\n",
    "        second_party:   second party name\n",
    "        fact:           fact text\n",
    "        \n",
    "    return:\n",
    "        cleaned fact\"\"\"\n",
    "    # 1. lower-case for the text, also remove some punctuations \n",
    "    first_party_text = first_party.lower().replace(',', '')\n",
    "    second_party_text = second_party.lower().replace(',', '')\n",
    "    fact_text = fact.lower().replace(',', '')\n",
    "    fact_text = fact_text.replace('<p>', '')\n",
    "    fact_text = fact_text.replace('</p>\\n', '')\n",
    "    # print(fact_text)\n",
    "\n",
    "    # 2. replace/remove the name of the first party and second party\n",
    "    first_party_split = [x for x in first_party_text.split(' ') if x.strip()]\n",
    "    second_party_split = [x for x in second_party_text.split(' ') if x.strip()]\n",
    "    first_second_party = first_party_split + second_party_split\n",
    "    # print(first_second_party)\n",
    "    fact_split = ' '.join([x for x in fact_text.split(' ') if x not in first_second_party])\n",
    "\n",
    "    # 3. remove punctuations and numbers\n",
    "    fact_clean = re.sub('[^a-zA-Z]', ' ', fact_split)\n",
    "\n",
    "    # 4. remove single character\n",
    "    fact_clean = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', fact_clean)\n",
    "\n",
    "    # 5. remove multiple spaces\n",
    "    fact_clean = re.sub(r'\\s+', ' ', fact_clean)\n",
    "\n",
    "    # 6. token \n",
    "    fact_clean = word_tokenize(fact_clean)\n",
    "\n",
    "    # 7. remove stop words\n",
    "    fact_clean = [word for word in fact_clean if word not in (stop)]\n",
    "\n",
    "    # 8. lemmatizer \n",
    "    # fact_clean = [lemmatizer.lemmatize(word) for word in fact_clean]\n",
    "\n",
    "    # join token to text \n",
    "    fact_clean = ' '.join(fact_clean)\n",
    "\n",
    "\n",
    "    return fact_clean\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "justice_data_new['Cleaned_Facts'] = justice_data_new.apply(lambda x: data_clean_1(x.first_party, x.second_party, x.facts), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "justice_data_new['Cleaned_Facts'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Feature engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 training data X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_facts = TfidfVectorizer()\n",
    "vectorizer_facts = vectorizer_facts.fit(justice_data_new['Cleaned_Facts'])\n",
    "facts_nlp_feature=vectorizer_facts.transform(justice_data_new['Cleaned_Facts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3286, 17556)\n"
     ]
    }
   ],
   "source": [
    "facts_nlp_feature_array = facts_nlp_feature.toarray()\n",
    "print(facts_nlp_feature_array.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 target labels--labelling the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "data_label = label_encoder.fit_transform(justice_data_new['first_party_winner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 0 1]\n",
      "(2139,) (1147,)\n"
     ]
    }
   ],
   "source": [
    "print(data_label)\n",
    "print(data_label[data_label==1].shape, data_label[data_label==0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2300, 17556) (986, 17556) (2300,) (986,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(facts_nlp_feature_array, data_label, test_size=0.3, random_state=42, shuffle=True)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:100]#[y_test==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(779,)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[y_train==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2300, 17400)\n",
      "(2300, 200, 87) (986, 200, 87)\n"
     ]
    }
   ],
   "source": [
    "input_length = 200\n",
    "word_nums = X_train.shape[1]//input_length\n",
    "print(X_train[:, 0:input_length*word_nums].shape)\n",
    "X_train_reshape = X_train[:,0:input_length*word_nums].reshape((-1,input_length,word_nums))\n",
    "X_test_reshape = X_test[:,0:input_length*word_nums].reshape((-1,input_length,word_nums))\n",
    "print(X_train_reshape.shape, X_test_reshape.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv1D(64,5, activation='relu', input_shape=(input_length, word_nums)))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=1,\n",
    "                                       padding='same'))\n",
    "model.add(tf.keras.layers.Conv1D(128,3,activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=1,\n",
    "                                       padding='same'))\n",
    "model.add(tf.keras.layers.Conv1D(256,5,activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=1,\n",
    "                                       padding='same'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "# model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "9/9 [==============================] - 7s 725ms/step - loss: 0.6694 - accuracy: 0.6396 - val_loss: 0.6808 - val_accuracy: 0.6268\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 6s 695ms/step - loss: 0.6640 - accuracy: 0.6613 - val_loss: 0.6695 - val_accuracy: 0.6268\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 6s 703ms/step - loss: 0.6429 - accuracy: 0.6613 - val_loss: 0.6603 - val_accuracy: 0.6268\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 6s 700ms/step - loss: 0.6404 - accuracy: 0.6613 - val_loss: 0.6619 - val_accuracy: 0.6268\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 7s 748ms/step - loss: 0.6373 - accuracy: 0.6613 - val_loss: 0.6648 - val_accuracy: 0.6268\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 6s 711ms/step - loss: 0.6360 - accuracy: 0.6613 - val_loss: 0.6607 - val_accuracy: 0.6268\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 6s 708ms/step - loss: 0.6329 - accuracy: 0.6613 - val_loss: 0.6635 - val_accuracy: 0.6268\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 7s 701ms/step - loss: 0.6280 - accuracy: 0.6613 - val_loss: 0.6614 - val_accuracy: 0.6268\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 6s 710ms/step - loss: 0.6202 - accuracy: 0.6617 - val_loss: 0.6673 - val_accuracy: 0.6258\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 7s 727ms/step - loss: 0.6103 - accuracy: 0.6604 - val_loss: 0.6842 - val_accuracy: 0.6278\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 6s 696ms/step - loss: 0.5966 - accuracy: 0.6722 - val_loss: 0.6851 - val_accuracy: 0.6176\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 6s 695ms/step - loss: 0.5839 - accuracy: 0.6848 - val_loss: 0.6786 - val_accuracy: 0.6105\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 7s 720ms/step - loss: 0.5631 - accuracy: 0.6939 - val_loss: 0.7188 - val_accuracy: 0.6156\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 6s 699ms/step - loss: 0.5497 - accuracy: 0.7126 - val_loss: 0.7213 - val_accuracy: 0.6075\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 8s 922ms/step - loss: 0.5211 - accuracy: 0.7296 - val_loss: 0.7159 - val_accuracy: 0.5882\n",
      "Epoch 16/50\n",
      "2/9 [=====>........................] - ETA: 5s - loss: 0.5085 - accuracy: 0.7656 "
     ]
    }
   ],
   "source": [
    "model.fit(X_train_reshape, y_train, epochs=50, validation_data=(X_test_reshape, y_test), batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 1s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "classifications= model.predict(X_test_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = classifications.argmax(axis=1)#[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6125760649087221"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true=y_test, y_pred=pred_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auto_judgement",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
