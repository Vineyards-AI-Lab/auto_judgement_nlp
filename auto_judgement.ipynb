{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/robert/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/robert/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# down load nltk data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# setting stopword\n",
    "stop = stopwords.words('english')\n",
    "stop.remove('no')\n",
    "stop.remove('not')\n",
    "\n",
    "# setting lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "justice_path = './dataset/'\n",
    "justice_data = pd.read_csv(os.path.join(justice_path,'justice.csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Preprocessing for Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 subset of interested columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_intersted = ['ID', \n",
    "                     'first_party',\n",
    "                     'second_party',\n",
    "                     'facts',\n",
    "                     'first_party_winner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "justice_data_new = justice_data[columns_intersted].copy(deep=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2A quick investigation of the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2762</th>\n",
       "      <td>61978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In Re Winship</td>\n",
       "      <td>&lt;p&gt;At age twelve, Samuel Winship was arrested ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID first_party   second_party  \\\n",
       "2762  61978         NaN  In Re Winship   \n",
       "\n",
       "                                                  facts first_party_winner  \n",
       "2762  <p>At age twelve, Samuel Winship was arrested ...               True  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "justice_data_new[justice_data_new['first_party'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>54848</td>\n",
       "      <td>In re Bauer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;Pro se petitioner Frederick W. Bauer sought...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  first_party second_party  \\\n",
       "1257  54848  In re Bauer          NaN   \n",
       "\n",
       "                                                  facts first_party_winner  \n",
       "1257  <p>Pro se petitioner Frederick W. Bauer sought...              False  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "justice_data_new[justice_data_new['second_party'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>51803</td>\n",
       "      <td>United States</td>\n",
       "      <td>California</td>\n",
       "      <td>&lt;p&gt;Channel Islands National Monument is a nati...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>54908</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>Maine</td>\n",
       "      <td>&lt;p&gt;In 1977, a dispute between New Hampshire an...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>55282</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>United States</td>\n",
       "      <td>&lt;p&gt;Alaska and the United States disputed owner...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>55334</td>\n",
       "      <td>Bank of China, New York Branch</td>\n",
       "      <td>NBM L.L.C., et al.</td>\n",
       "      <td>&lt;p&gt;Bank of China alleged that John Chou and Sh...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>55514</td>\n",
       "      <td>State of New Jersey</td>\n",
       "      <td>State of Delaware</td>\n",
       "      <td>&lt;p&gt;When British Petroleum (BP) wanted to build...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>55652</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>&lt;p&gt;Several states belonging to the Southeast I...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>55781</td>\n",
       "      <td>Montana</td>\n",
       "      <td>Wyoming and North Dakota</td>\n",
       "      <td>&lt;p&gt;1950, Montana, Wyoming and North Dakota sig...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2528</th>\n",
       "      <td>60033</td>\n",
       "      <td>Dusky</td>\n",
       "      <td>United States</td>\n",
       "      <td>&lt;p&gt;Dusky was charged with kidnapping and rape....</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2631</th>\n",
       "      <td>61030</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>Katzenbach</td>\n",
       "      <td>&lt;p&gt;The Voting Rights Act of 1965 prevented sta...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2787</th>\n",
       "      <td>62121</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>&lt;p&gt;The Louisiana State Constitution and Code o...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>62377</td>\n",
       "      <td>The Civil Rights Cases</td>\n",
       "      <td>Various appellants</td>\n",
       "      <td>&lt;p&gt;The Civil Rights Act of 1875 affirmed the e...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903</th>\n",
       "      <td>62500</td>\n",
       "      <td>Albert Yakus</td>\n",
       "      <td>United States</td>\n",
       "      <td>&lt;p&gt;In 1942, Congress enacted the Emergency Pri...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3080</th>\n",
       "      <td>62911</td>\n",
       "      <td>State of Texas</td>\n",
       "      <td>State of New Mexico and State of Colorado</td>\n",
       "      <td>&lt;p&gt;The Rio Grande originates in Colorado, flow...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3183</th>\n",
       "      <td>63090</td>\n",
       "      <td>New York State Rifle and Pistol Association, I...</td>\n",
       "      <td>City of New York, New York, et al.</td>\n",
       "      <td>&lt;p&gt;The State of New York law prohibits the pos...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3203</th>\n",
       "      <td>63137</td>\n",
       "      <td>Retirement Plans Committee of IBM, et al.</td>\n",
       "      <td>Larry W. Jander, et al.</td>\n",
       "      <td>&lt;p&gt;In &lt;a href=\"https://www.oyez.org/cases/2013...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                        first_party  \\\n",
       "223   51803                                      United States   \n",
       "1322  54908                                      New Hampshire   \n",
       "1674  55282                                             Alaska   \n",
       "1721  55334                     Bank of China, New York Branch   \n",
       "1890  55514                                State of New Jersey   \n",
       "2023  55652                                            Alabama   \n",
       "2137  55781                                            Montana   \n",
       "2528  60033                                              Dusky   \n",
       "2631  61030                                     South Carolina   \n",
       "2787  62121                                            Johnson   \n",
       "2875  62377                             The Civil Rights Cases   \n",
       "2903  62500                                       Albert Yakus   \n",
       "3080  62911                                     State of Texas   \n",
       "3183  63090  New York State Rifle and Pistol Association, I...   \n",
       "3203  63137          Retirement Plans Committee of IBM, et al.   \n",
       "\n",
       "                                   second_party  \\\n",
       "223                                  California   \n",
       "1322                                      Maine   \n",
       "1674                              United States   \n",
       "1721                         NBM L.L.C., et al.   \n",
       "1890                          State of Delaware   \n",
       "2023                             North Carolina   \n",
       "2137                   Wyoming and North Dakota   \n",
       "2528                              United States   \n",
       "2631                                 Katzenbach   \n",
       "2787                                  Louisiana   \n",
       "2875                         Various appellants   \n",
       "2903                              United States   \n",
       "3080  State of New Mexico and State of Colorado   \n",
       "3183         City of New York, New York, et al.   \n",
       "3203                    Larry W. Jander, et al.   \n",
       "\n",
       "                                                  facts first_party_winner  \n",
       "223   <p>Channel Islands National Monument is a nati...                NaN  \n",
       "1322  <p>In 1977, a dispute between New Hampshire an...                NaN  \n",
       "1674  <p>Alaska and the United States disputed owner...                NaN  \n",
       "1721  <p>Bank of China alleged that John Chou and Sh...                NaN  \n",
       "1890  <p>When British Petroleum (BP) wanted to build...                NaN  \n",
       "2023  <p>Several states belonging to the Southeast I...                NaN  \n",
       "2137  <p>1950, Montana, Wyoming and North Dakota sig...                NaN  \n",
       "2528  <p>Dusky was charged with kidnapping and rape....                NaN  \n",
       "2631  <p>The Voting Rights Act of 1965 prevented sta...                NaN  \n",
       "2787  <p>The Louisiana State Constitution and Code o...                NaN  \n",
       "2875  <p>The Civil Rights Act of 1875 affirmed the e...                NaN  \n",
       "2903  <p>In 1942, Congress enacted the Emergency Pri...                NaN  \n",
       "3080  <p>The Rio Grande originates in Colorado, flow...                NaN  \n",
       "3183  <p>The State of New York law prohibits the pos...                NaN  \n",
       "3203  <p>In <a href=\"https://www.oyez.org/cases/2013...                NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "justice_data_new[justice_data_new['first_party_winner'].isna()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a results, there are NaN values in our data. We should remove/drop these noise rows."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 drop the rows with NaN or missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "justice_data_new.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50606</td>\n",
       "      <td>Jane Roe</td>\n",
       "      <td>Henry Wade</td>\n",
       "      <td>&lt;p&gt;In 1970, Jane Roe (a fictional name used in...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50613</td>\n",
       "      <td>Peter Stanley, Sr.</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>&lt;p&gt;Joan Stanley had three children with Peter ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50623</td>\n",
       "      <td>John Giglio</td>\n",
       "      <td>United States</td>\n",
       "      <td>&lt;p&gt;John Giglio was convicted of passing forged...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50632</td>\n",
       "      <td>Sally Reed</td>\n",
       "      <td>Cecil Reed</td>\n",
       "      <td>&lt;p&gt;The Idaho Probate Code specified that \"male...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50643</td>\n",
       "      <td>Marvin Miller</td>\n",
       "      <td>California</td>\n",
       "      <td>&lt;p&gt;Miller, after conducting a mass mailing cam...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3298</th>\n",
       "      <td>63324</td>\n",
       "      <td>United States</td>\n",
       "      <td>Refugio Palomar-Santiago</td>\n",
       "      <td>&lt;p&gt;Refugio Palomar-Santiago, a Mexican nationa...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3299</th>\n",
       "      <td>63323</td>\n",
       "      <td>Tarahrick Terry</td>\n",
       "      <td>United States</td>\n",
       "      <td>&lt;p&gt;Tarahrick Terry pleaded guilty to one count...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3300</th>\n",
       "      <td>63331</td>\n",
       "      <td>United States</td>\n",
       "      <td>Joshua James Cooley</td>\n",
       "      <td>&lt;p&gt;Joshua James Cooley was parked in his picku...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3301</th>\n",
       "      <td>63332</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>&lt;p&gt;This is an ongoing case of original jurisdi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3302</th>\n",
       "      <td>63335</td>\n",
       "      <td>PennEast Pipeline Co. LLC</td>\n",
       "      <td>New Jersey, et al.</td>\n",
       "      <td>&lt;p&gt;The Natural Gas Act (NGA), 15 U.S.C. §§ 717...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3286 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                first_party              second_party  \\\n",
       "0     50606                   Jane Roe                Henry Wade   \n",
       "1     50613        Peter Stanley, Sr.                   Illinois   \n",
       "2     50623               John Giglio              United States   \n",
       "3     50632                 Sally Reed                Cecil Reed   \n",
       "4     50643              Marvin Miller                California   \n",
       "...     ...                        ...                       ...   \n",
       "3298  63324              United States  Refugio Palomar-Santiago   \n",
       "3299  63323            Tarahrick Terry             United States   \n",
       "3300  63331              United States       Joshua James Cooley   \n",
       "3301  63332                    Florida                   Georgia   \n",
       "3302  63335  PennEast Pipeline Co. LLC        New Jersey, et al.   \n",
       "\n",
       "                                                  facts first_party_winner  \n",
       "0     <p>In 1970, Jane Roe (a fictional name used in...               True  \n",
       "1     <p>Joan Stanley had three children with Peter ...               True  \n",
       "2     <p>John Giglio was convicted of passing forged...               True  \n",
       "3     <p>The Idaho Probate Code specified that \"male...               True  \n",
       "4     <p>Miller, after conducting a mass mailing cam...               True  \n",
       "...                                                 ...                ...  \n",
       "3298  <p>Refugio Palomar-Santiago, a Mexican nationa...               True  \n",
       "3299  <p>Tarahrick Terry pleaded guilty to one count...              False  \n",
       "3300  <p>Joshua James Cooley was parked in his picku...               True  \n",
       "3301  <p>This is an ongoing case of original jurisdi...              False  \n",
       "3302  <p>The Natural Gas Act (NGA), 15 U.S.C. §§ 717...               True  \n",
       "\n",
       "[3286 rows x 5 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "justice_data_new#['facts'][1]#[justice_data_new['second_party'].isna()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clean(text):\n",
    "  text = text.lower()\n",
    "  text = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?|p\", \"\", text)\n",
    "  text_tokens = word_tokenize(text)\n",
    "  text_stop = [word for word in text_tokens if word not in (stop)]\n",
    "  text_new = ' '.join(text_stop)\n",
    "  return text_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clean_1(first_party, second_party, fact):\n",
    "    \"\"\"This is to clean the facts. Will remove the first party and second party name\n",
    "    \n",
    "    Args:\n",
    "        first_party:    first party name\n",
    "        second_party:   second party name\n",
    "        fact:           fact text\n",
    "        \n",
    "    return:\n",
    "        cleaned fact\"\"\"\n",
    "    # 1. lower-case for the text, also remove some punctuations \n",
    "    first_party_text = first_party.lower().replace(',', '')\n",
    "    second_party_text = second_party.lower().replace(',', '')\n",
    "    fact_text = fact.lower().replace(',', '')\n",
    "    fact_text = fact_text.replace('<p>', '')\n",
    "    fact_text = fact_text.replace('</p>\\n', '')\n",
    "    # print(fact_text)\n",
    "\n",
    "    # 2. replace/remove the name of the first party and second party\n",
    "    first_party_split = [x for x in first_party_text.split(' ') if x.strip()]\n",
    "    second_party_split = [x for x in second_party_text.split(' ') if x.strip()]\n",
    "    first_second_party = first_party_split + second_party_split\n",
    "    # print(first_second_party)\n",
    "    fact_split = ' '.join([x for x in fact_text.split(' ') if x not in first_second_party])\n",
    "\n",
    "    # 3. remove punctuations and numbers\n",
    "    fact_clean = re.sub('[^a-zA-Z]', ' ', fact_split)\n",
    "\n",
    "    # 4. remove single character\n",
    "    fact_clean = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', fact_clean)\n",
    "\n",
    "    # 5. remove multiple spaces\n",
    "    fact_clean = re.sub(r'\\s+', ' ', fact_clean)\n",
    "\n",
    "    # 6. token \n",
    "    fact_clean = word_tokenize(fact_clean)\n",
    "\n",
    "    # 7. remove stop words\n",
    "    fact_clean = [word for word in fact_clean if word not in (stop)]\n",
    "\n",
    "    # 8. lemmatizer \n",
    "    # fact_clean = [lemmatizer.lemmatize(word) for word in fact_clean]\n",
    "\n",
    "    # join token to text \n",
    "    fact_clean = ' '.join(fact_clean)\n",
    "\n",
    "\n",
    "    return fact_clean\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "justice_data_new['Cleaned_Facts'] = justice_data_new.apply(lambda x: data_clean_1(x.first_party, x.second_party, x.facts), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "justice_data_new['Cleaned_Facts'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Feature engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 training data X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_facts = TfidfVectorizer()\n",
    "vectorizer_facts = vectorizer_facts.fit(justice_data_new['Cleaned_Facts'])\n",
    "facts_nlp_feature=vectorizer_facts.transform(justice_data_new['Cleaned_Facts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3286, 17556)\n"
     ]
    }
   ],
   "source": [
    "facts_nlp_feature_array = facts_nlp_feature.toarray()\n",
    "print(facts_nlp_feature_array.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 target labels--labelling the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "data_label = label_encoder.fit_transform(justice_data_new['first_party_winner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 0 1]\n",
      "(2139,) (1147,)\n"
     ]
    }
   ],
   "source": [
    "print(data_label)\n",
    "print(data_label[data_label==1].shape, data_label[data_label==0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2300, 17556) (986, 17556) (2300,) (986,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(facts_nlp_feature_array, data_label, test_size=0.3, random_state=42, shuffle=True)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:100]#[y_test==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(779,)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[y_train==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2300, 17400)\n",
      "(2300, 200, 87) (986, 200, 87)\n"
     ]
    }
   ],
   "source": [
    "input_length = 200\n",
    "word_nums = X_train.shape[1]//input_length\n",
    "print(X_train[:, 0:input_length*word_nums].shape)\n",
    "X_train_reshape = X_train[:,0:input_length*word_nums].reshape((-1,input_length,word_nums))\n",
    "X_test_reshape = X_test[:,0:input_length*word_nums].reshape((-1,input_length,word_nums))\n",
    "print(X_train_reshape.shape, X_test_reshape.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv1D(64,5, activation='relu', input_shape=(input_length, word_nums)))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=1,\n",
    "                                       padding='same'))\n",
    "model.add(tf.keras.layers.Conv1D(128,3,activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=1,\n",
    "                                       padding='same'))\n",
    "model.add(tf.keras.layers.Conv1D(256,5,activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=2,strides=1,\n",
    "                                       padding='same'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "# model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "9/9 [==============================] - 7s 712ms/step - loss: 0.6522 - accuracy: 0.6530 - val_loss: 0.6766 - val_accuracy: 0.6268\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 6s 691ms/step - loss: 0.6446 - accuracy: 0.6613 - val_loss: 0.6727 - val_accuracy: 0.6268\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 6s 681ms/step - loss: 0.6424 - accuracy: 0.6613 - val_loss: 0.6592 - val_accuracy: 0.6268\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 6s 682ms/step - loss: 0.6337 - accuracy: 0.6613 - val_loss: 0.6683 - val_accuracy: 0.6268\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 6s 731ms/step - loss: 0.6292 - accuracy: 0.6613 - val_loss: 0.6623 - val_accuracy: 0.6268\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 6s 701ms/step - loss: 0.6189 - accuracy: 0.6626 - val_loss: 0.6624 - val_accuracy: 0.6227\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 6s 698ms/step - loss: 0.6041 - accuracy: 0.6661 - val_loss: 0.6648 - val_accuracy: 0.6105\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 6s 698ms/step - loss: 0.5998 - accuracy: 0.6739 - val_loss: 0.6609 - val_accuracy: 0.6055\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 6s 706ms/step - loss: 0.5779 - accuracy: 0.6848 - val_loss: 0.6669 - val_accuracy: 0.6024\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 7s 751ms/step - loss: 0.5606 - accuracy: 0.7109 - val_loss: 0.6737 - val_accuracy: 0.6126\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 7s 728ms/step - loss: 0.5218 - accuracy: 0.7322 - val_loss: 0.7072 - val_accuracy: 0.6237\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 6s 729ms/step - loss: 0.4779 - accuracy: 0.7709 - val_loss: 0.7555 - val_accuracy: 0.6187\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 6s 697ms/step - loss: 0.4335 - accuracy: 0.7987 - val_loss: 0.7405 - val_accuracy: 0.5852\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 6s 684ms/step - loss: 0.3766 - accuracy: 0.8413 - val_loss: 0.8012 - val_accuracy: 0.5852\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 7s 742ms/step - loss: 0.3218 - accuracy: 0.8813 - val_loss: 0.9458 - val_accuracy: 0.6156\n",
      "Epoch 16/50\n",
      "5/9 [===============>..............] - ETA: 2s - loss: 0.2714 - accuracy: 0.9000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[226], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train_reshape, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_test_reshape, y_test), batch_size\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/auto_judgement/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/auto_judgement/lib/python3.9/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/auto_judgement/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/auto_judgement/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/auto_judgement/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/auto_judgement/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/auto_judgement/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/auto_judgement/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/auto_judgement/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train_reshape, y_train, epochs=50, validation_data=(X_test_reshape, y_test), batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 1s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "classifications= model.predict(X_test_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = classifications.argmax(axis=1)#[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6125760649087221"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true=y_test, y_pred=pred_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auto_judgement",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
